{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Importing libraries"
      ],
      "metadata": {
        "id": "c2GYKpMj-GNh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, roc_curve, auc\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.cluster import KMeans\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from scipy.stats import mode"
      ],
      "metadata": {
        "id": "8IIb2Uuyvj2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load & Filter Data"
      ],
      "metadata": {
        "id": "ntRIHcE--KJZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# Use first 5 classes only (0–4)\n",
        "mask_train = y_train_full < 5\n",
        "mask_test = y_test < 5\n",
        "\n",
        "X_train_full = X_train_full[mask_train]\n",
        "y_train_full = y_train_full[mask_train]\n",
        "\n",
        "X_test = X_test[mask_test]\n",
        "y_test = y_test[mask_test]"
      ],
      "metadata": {
        "id": "p4Ogj2-38RF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normalize Data"
      ],
      "metadata": {
        "id": "X4HwauoO-NBh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_full = X_train_full.astype('float32') / 255.0\n",
        "X_test = X_test.astype('float32') / 255.0\n",
        "\n",
        "# Flatten from (28x28) → (784)\n",
        "X_train_full = X_train_full.reshape(X_train_full.shape[0], -1)\n",
        "X_test = X_test.reshape(X_test.shape[0], -1)"
      ],
      "metadata": {
        "id": "iG6gQ8de8WG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split Train/Validation"
      ],
      "metadata": {
        "id": "Vh1mbipy-Vhw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train_full, y_train_full, test_size=0.2, random_state=42, stratify=y_train_full\n",
        ")"
      ],
      "metadata": {
        "id": "YX3CZlFC8aNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Standardize"
      ],
      "metadata": {
        "id": "Voy_QJ39-khE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"Training samples:\", X_train.shape[0])\n",
        "print(\"Validation samples:\", X_val.shape[0])\n",
        "print(\"Testing samples:\", X_test.shape[0])"
      ],
      "metadata": {
        "id": "lCiqFKXB80xh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementing Logistic Regression"
      ],
      "metadata": {
        "id": "B7GzwEly-Whe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_model = SGDClassifier(\n",
        "    loss='log_loss',\n",
        "    learning_rate='constant',\n",
        "    eta0=0.0001,\n",
        "    max_iter=1,\n",
        "    warm_start=True,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "train_loss = []\n",
        "val_loss = []\n",
        "epochs = 30\n",
        "classes = np.unique(y_train)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    lr_model.partial_fit(X_train_scaled, y_train, classes=classes)\n",
        "\n",
        "    y_train_prob = lr_model.predict_proba(X_train_scaled)\n",
        "    y_val_prob = lr_model.predict_proba(X_val_scaled)\n",
        "\n",
        "    train_loss.append(log_loss(y_train, y_train_prob))\n",
        "    val_loss.append(log_loss(y_val, y_val_prob))\n",
        "\n",
        "y_pred_lr = lr_model.predict(X_test_scaled)\n",
        "acc_lr = accuracy_score(y_test, y_pred_lr)\n",
        "print(f\"Logistic Regression Accuracy: {acc_lr:.4f}\")"
      ],
      "metadata": {
        "id": "xlh75vMV81Q-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting the Loss Curve"
      ],
      "metadata": {
        "id": "4Obq5Opw-ukA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(range(1, epochs+1), train_loss, label='Training Loss')\n",
        "plt.plot(range(1, epochs+1), val_loss, label='Validation Loss')\n",
        "plt.title(\"Logistic Regression Loss Curve\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Log Loss\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CG9Icb-69eNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting the Confusion Matrix"
      ],
      "metadata": {
        "id": "7IXIhWyh-znn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm_lr = confusion_matrix(y_test, y_pred_lr)\n",
        "disp_lr = ConfusionMatrixDisplay(confusion_matrix=cm_lr, display_labels=np.arange(5))\n",
        "disp_lr.plot(cmap=plt.cm.Blues)\n",
        "plt.title(\"Logistic Regression Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4p6XzqiV9hJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting the Confusion Matrix"
      ],
      "metadata": {
        "id": "F9I1GaTb-0GA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_scores = lr_model.predict_proba(X_test_scaled)\n",
        "fpr = {}\n",
        "tpr = {}\n",
        "roc_auc = {}\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "for i in range(5):\n",
        "    fpr[i], tpr[i], _ = roc_curve((y_test == i).astype(int), y_scores[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "    plt.plot(fpr[i], tpr[i], label=f\"Class {i} AUC = {roc_auc[i]:.3f}\")\n",
        "\n",
        "plt.plot([0, 1], [0, 1], \"k--\")\n",
        "plt.title(\"Logistic Regression ROC Curve\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FRCk3J5H9j-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementing K-Means Clustering"
      ],
      "metadata": {
        "id": "VeMoeCjT_GaU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans = KMeans(n_clusters=5, random_state=42)\n",
        "kmeans.fit(X_train_scaled)\n",
        "\n",
        "# Predict clusters\n",
        "clusters = kmeans.predict(X_test_scaled)\n",
        "\n",
        "# Map clusters to real labels using training set\n",
        "train_clusters = kmeans.predict(X_train_scaled)\n",
        "from scipy.stats import mode\n",
        "\n",
        "labels_map = {}\n",
        "for c in range(5):\n",
        "    mask = (train_clusters == c)\n",
        "    if np.sum(mask) == 0:\n",
        "        labels_map[c] = 0\n",
        "    else:\n",
        "        m = mode(y_train[mask], keepdims=True)\n",
        "        if hasattr(m, 'mode'):\n",
        "            labels_map[c] = m.mode[0] if not np.isscalar(m.mode) else m.mode\n",
        "        else:\n",
        "            labels_map[c] = m[0][0]\n",
        "\n",
        "# Final K-Means prediction\n",
        "y_pred_kmeans = np.array([labels_map[c] for c in clusters])\n",
        "\n",
        "acc_kmeans = accuracy_score(y_test, y_pred_kmeans)\n",
        "print(\"\\n==============================\")\n",
        "print(\"K-Means Accuracy (mapped):\", acc_kmeans)\n",
        "print(\"==============================\\n\")"
      ],
      "metadata": {
        "id": "vU1m8PHE82mM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting the Confusion Matrix"
      ],
      "metadata": {
        "id": "KmiHRuKx_Jz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm_kmeans = confusion_matrix(y_test, y_pred_kmeans)\n",
        "disp_kmeans = ConfusionMatrixDisplay(confusion_matrix=cm_kmeans, display_labels=np.arange(5))\n",
        "disp_kmeans.plot(cmap=plt.cm.Oranges)\n",
        "plt.title(\"K-Means Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aAxpPvEA90wb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}